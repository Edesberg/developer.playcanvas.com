"use strict";(self.webpackChunkdeveloper_playcanvas_com=self.webpackChunkdeveloper_playcanvas_com||[]).push([[3986],{50628:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>t,default:()=>h,frontMatter:()=>i,metadata:()=>o,toc:()=>c});var s=r(85893),a=r(11151);const i={title:"Capabilities",sidebar_position:4},t=void 0,o={id:"user-manual/xr/capabilities",title:"Capabilities",description:"WebXR exposes various capabilities and new APIs through Modules, which are integrated into the PlayCanvas Engine for ease of use. The currently supported WebXR APIs are:",source:"@site/docs/user-manual/xr/capabilities.md",sourceDirName:"user-manual/xr",slug:"/user-manual/xr/capabilities",permalink:"/ja/user-manual/xr/capabilities",draft:!1,unlisted:!1,editUrl:"https://github.com/playcanvas/developer.playcanvas.com/tree/dev/docs/user-manual/xr/capabilities.md",tags:[],version:"current",sidebarPosition:4,frontMatter:{title:"Capabilities",sidebar_position:4},sidebar:"userManualSidebar",previous:{title:"VR\u4f53\u9a13\u306e\u7a2e\u985e",permalink:"/ja/user-manual/xr/vr/types-of-vr"},next:{title:"PlayCanvas\u306b\u304a\u3051\u308bWebXR Input Sources",permalink:"/ja/user-manual/xr/input-sources"}},l={},c=[];function d(e){const n={a:"a",li:"li",p:"p",strong:"strong",ul:"ul",...(0,a.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.p,{children:"WebXR exposes various capabilities and new APIs through Modules, which are integrated into the PlayCanvas Engine for ease of use. The currently supported WebXR APIs are:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsxs)(n.strong,{children:["Immersive ",(0,s.jsx)(n.a,{href:"/user-manual/xr/vr/",children:"VR"})," and ",(0,s.jsx)(n.a,{href:"/user-manual/xr/ar/",children:"AR"})]})," session types."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"/user-manual/xr/ar/anchors/",children:(0,s.jsx)(n.strong,{children:"Anchors"})})," - create anchors in space that are reliably positioned in relation to real-world geometry."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"/user-manual/xr/ar/anchors/#persistence",children:(0,s.jsx)(n.strong,{children:"Persistent Anchors"})})," - allows to persist anchors between sessions."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"/user-manual/xr/ar/camera-color/",children:(0,s.jsx)(n.strong,{children:"Camera Color"})})," - provides access to a color texture of a view."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Depth Sensing"})," - provides access to depth texture and distance querying, that can be used for virtual object occlusion with real-world geometry and reliable object placement."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"/user-manual/xr/ar/dom-overlay/",children:(0,s.jsx)(n.strong,{children:"DOM Overlay"})})," - for monoscopic screens, allows to overlay DOM elements over an AR view."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Hand Tracking"})," - optical hand tracking that tracks each joint of a hand."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Hit Testing"})," - allows to ray cast real-world geometry using a ray, to get position and rotation of the intersection point."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Image Tracking"})," - dynamic tracking of provided images, their position, and orientation."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"/user-manual/xr/input-sources/",children:(0,s.jsx)(n.strong,{children:"Input Sources"})})," - various input source types such as controllers, hands, screen taps, gaze, and more."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Light Estimation"})," - estimates real-world illumination by providing dominant directional light direction, color, and intensity as well as ambient light information in the form of spherical harmonics."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Mesh Detection"})," - access to a representation of a real-world geometry in the form of a 3D mesh, with its position, orientation, and semantic labels. This can represent furniture, screens, rooms, and other types of static geometry."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Plane Detection"})," - similar to mesh detection, that provides geometry in the form of planes, their position, orientation, vertices, and semantic labels. This can represent large flat surfaces, such as floors, walls, ceilings, windows, doors, and more."]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,a.a)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},11151:(e,n,r)=>{r.d(n,{Z:()=>o,a:()=>t});var s=r(67294);const a={},i=s.createContext(a);function t(e){const n=s.useContext(i);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:t(e.components),s.createElement(i.Provider,{value:n},e.children)}}}]);